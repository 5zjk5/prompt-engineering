# 上下文工程

上下文工程是指管理和优化发送给大语言模型的信息，以确保模型能够获得正确的上下文并生成准确、相关的响应。这包括消息管理、系统提示优化、记忆管理等多个方面。

**重要说明**：结构化输出和短期记忆也属于上下文工程的范畴。结构化输出通过定义明确的响应格式来约束模型输出，确保结果的一致性和可用性；短期记忆通过管理对话历史来保持上下文的连贯性，两者都是上下文工程的重要组成部分。

## 文件说明

### messages.py
消息管理示例，展示了如何通过中间件动态注入和管理发送给LLM的消息内容。包含两个主要示例：

1. **文件上下文注入** (`inject_file_context`)：从状态中获取用户上传的文件信息，并将文件描述注入到消息中，使模型能够引用这些文件回答问题。

2. **写作风格注入** (`inject_writing_style`)：从长期记忆存储中获取用户的写作风格示例，并将风格指南注入到消息中，指导模型按照用户偏好生成内容。

关键代码展示了如何覆盖请求中的消息、工具和模型：
```python
request = request.override(messages=messages)  # 覆盖请求中的消息  
request = request.override(tools=tools)  # 修改请求中的工具  
request = request.override(model=model)  # 修改模型
request = request.override(response_format=SimpleResponse)  # 修改响应格式
```

### system_prompt.py
系统提示管理示例，展示了如何根据不同情境动态调整系统提示。包含两个主要示例：

1. **状态感知提示** (`state_aware_prompt`)：根据对话中的消息数量动态调整系统提示，例如在长对话中提示模型更加简洁。

2. **存储感知提示** (`store_aware_prompt`)：从长期记忆中获取用户偏好，并根据这些偏好调整系统提示，例如根据用户偏好的沟通风格调整响应方式。

这两个示例都使用了 `@dynamic_prompt` 装饰器，它允许根据请求的上下文动态生成系统提示，而不是使用固定的提示文本。
